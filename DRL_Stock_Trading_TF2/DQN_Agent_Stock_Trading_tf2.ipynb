{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN_Agent_Stock_Trading_tf2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq8nVfecmAs8",
        "colab_type": "text"
      },
      "source": [
        "# **Import library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uPyTLXX3ikh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3ad59a06-46a6-45d2-a671-e7534195e01b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import random\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5V6KQMGmFsN",
        "colab_type": "text"
      },
      "source": [
        "# **Read stock dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HXK9NbYl5Qs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "c7c51e9b-4fea-4aa0-af4b-453b0eca09da"
      },
      "source": [
        "# Using dataset from txt file\n",
        "data = pd.read_csv('googl.us.txt')\n",
        "data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>OpenInt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2004-08-19</td>\n",
              "      <td>50.000</td>\n",
              "      <td>52.03</td>\n",
              "      <td>47.980</td>\n",
              "      <td>50.170</td>\n",
              "      <td>44703800</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2004-08-20</td>\n",
              "      <td>50.505</td>\n",
              "      <td>54.54</td>\n",
              "      <td>50.250</td>\n",
              "      <td>54.155</td>\n",
              "      <td>22857200</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2004-08-23</td>\n",
              "      <td>55.375</td>\n",
              "      <td>56.74</td>\n",
              "      <td>54.525</td>\n",
              "      <td>54.700</td>\n",
              "      <td>18274400</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2004-08-24</td>\n",
              "      <td>55.620</td>\n",
              "      <td>55.80</td>\n",
              "      <td>51.785</td>\n",
              "      <td>52.435</td>\n",
              "      <td>15262600</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004-08-25</td>\n",
              "      <td>52.480</td>\n",
              "      <td>54.00</td>\n",
              "      <td>51.940</td>\n",
              "      <td>53.000</td>\n",
              "      <td>9197800</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3328</th>\n",
              "      <td>2017-11-06</td>\n",
              "      <td>1049.100</td>\n",
              "      <td>1052.59</td>\n",
              "      <td>1042.000</td>\n",
              "      <td>1042.680</td>\n",
              "      <td>913954</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3329</th>\n",
              "      <td>2017-11-07</td>\n",
              "      <td>1049.650</td>\n",
              "      <td>1053.41</td>\n",
              "      <td>1043.000</td>\n",
              "      <td>1052.390</td>\n",
              "      <td>1303832</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3330</th>\n",
              "      <td>2017-11-08</td>\n",
              "      <td>1050.050</td>\n",
              "      <td>1062.69</td>\n",
              "      <td>1047.050</td>\n",
              "      <td>1058.290</td>\n",
              "      <td>1214469</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3331</th>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>1048.000</td>\n",
              "      <td>1050.88</td>\n",
              "      <td>1035.850</td>\n",
              "      <td>1047.720</td>\n",
              "      <td>1793994</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332</th>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>1043.870</td>\n",
              "      <td>1046.63</td>\n",
              "      <td>1041.220</td>\n",
              "      <td>1044.150</td>\n",
              "      <td>970498</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3333 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date      Open     High       Low     Close    Volume  OpenInt\n",
              "0     2004-08-19    50.000    52.03    47.980    50.170  44703800        0\n",
              "1     2004-08-20    50.505    54.54    50.250    54.155  22857200        0\n",
              "2     2004-08-23    55.375    56.74    54.525    54.700  18274400        0\n",
              "3     2004-08-24    55.620    55.80    51.785    52.435  15262600        0\n",
              "4     2004-08-25    52.480    54.00    51.940    53.000   9197800        0\n",
              "...          ...       ...      ...       ...       ...       ...      ...\n",
              "3328  2017-11-06  1049.100  1052.59  1042.000  1042.680    913954        0\n",
              "3329  2017-11-07  1049.650  1053.41  1043.000  1052.390   1303832        0\n",
              "3330  2017-11-08  1050.050  1062.69  1047.050  1058.290   1214469        0\n",
              "3331  2017-11-09  1048.000  1050.88  1035.850  1047.720   1793994        0\n",
              "3332  2017-11-10  1043.870  1046.63  1041.220  1044.150    970498        0\n",
              "\n",
              "[3333 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrqV-soiDPRg",
        "colab_type": "text"
      },
      "source": [
        "To benchmark with the paper, we will use the data stock price of Google from 01-Jan-2015 to 10-November-2017. Since 01-Jan-2015 was public holiday and no trading on that day, therefore, price at 02-Jan-2015 is used as starting point for training. The **training set** is from date 02-January-2015 until 31-December-2016 and total **504 sample points**. Period of time from 01-January-2017 until 10-November-2017 as **testing set** which has **218 samples**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uukWQoIanv6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_index(date):\n",
        "  for no, i in enumerate(data.Date):\n",
        "    if i == date:\n",
        "      index = no\n",
        "  return index"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGJ2z1b-IVJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get index from training and testing period\n",
        "train_start_index = get_index('2015-01-02')\n",
        "train_end_index = get_index('2016-12-30')\n",
        "test_start_index = get_index('2017-01-03')\n",
        "test_end_index = get_index('2017-11-10')\n",
        "\n",
        "train_set = data[train_start_index:train_end_index + 1]\n",
        "test_set = data[test_start_index:test_end_index + 1]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sgDoV-bEJOa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "92bdcc5c-676a-43ff-a2cc-777271a95f0f"
      },
      "source": [
        "train_set"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>OpenInt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2611</th>\n",
              "      <td>2015-01-02</td>\n",
              "      <td>532.60</td>\n",
              "      <td>535.800</td>\n",
              "      <td>527.880</td>\n",
              "      <td>529.55</td>\n",
              "      <td>1327665</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2612</th>\n",
              "      <td>2015-01-05</td>\n",
              "      <td>527.15</td>\n",
              "      <td>527.990</td>\n",
              "      <td>517.750</td>\n",
              "      <td>519.46</td>\n",
              "      <td>2057089</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2613</th>\n",
              "      <td>2015-01-06</td>\n",
              "      <td>520.50</td>\n",
              "      <td>521.210</td>\n",
              "      <td>505.550</td>\n",
              "      <td>506.64</td>\n",
              "      <td>2731728</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2614</th>\n",
              "      <td>2015-01-07</td>\n",
              "      <td>510.95</td>\n",
              "      <td>511.490</td>\n",
              "      <td>503.650</td>\n",
              "      <td>505.15</td>\n",
              "      <td>2345823</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2615</th>\n",
              "      <td>2015-01-08</td>\n",
              "      <td>501.16</td>\n",
              "      <td>507.500</td>\n",
              "      <td>495.020</td>\n",
              "      <td>506.91</td>\n",
              "      <td>3662169</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3110</th>\n",
              "      <td>2016-12-23</td>\n",
              "      <td>808.01</td>\n",
              "      <td>810.970</td>\n",
              "      <td>805.110</td>\n",
              "      <td>807.80</td>\n",
              "      <td>750685</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3111</th>\n",
              "      <td>2016-12-27</td>\n",
              "      <td>808.68</td>\n",
              "      <td>816.000</td>\n",
              "      <td>805.800</td>\n",
              "      <td>809.93</td>\n",
              "      <td>946336</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3112</th>\n",
              "      <td>2016-12-28</td>\n",
              "      <td>813.33</td>\n",
              "      <td>813.330</td>\n",
              "      <td>802.440</td>\n",
              "      <td>804.57</td>\n",
              "      <td>1159794</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3113</th>\n",
              "      <td>2016-12-29</td>\n",
              "      <td>802.33</td>\n",
              "      <td>805.750</td>\n",
              "      <td>798.144</td>\n",
              "      <td>802.83</td>\n",
              "      <td>998255</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3114</th>\n",
              "      <td>2016-12-30</td>\n",
              "      <td>803.21</td>\n",
              "      <td>803.285</td>\n",
              "      <td>789.620</td>\n",
              "      <td>792.45</td>\n",
              "      <td>1735879</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>504 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date    Open     High      Low   Close   Volume  OpenInt\n",
              "2611  2015-01-02  532.60  535.800  527.880  529.55  1327665        0\n",
              "2612  2015-01-05  527.15  527.990  517.750  519.46  2057089        0\n",
              "2613  2015-01-06  520.50  521.210  505.550  506.64  2731728        0\n",
              "2614  2015-01-07  510.95  511.490  503.650  505.15  2345823        0\n",
              "2615  2015-01-08  501.16  507.500  495.020  506.91  3662169        0\n",
              "...          ...     ...      ...      ...     ...      ...      ...\n",
              "3110  2016-12-23  808.01  810.970  805.110  807.80   750685        0\n",
              "3111  2016-12-27  808.68  816.000  805.800  809.93   946336        0\n",
              "3112  2016-12-28  813.33  813.330  802.440  804.57  1159794        0\n",
              "3113  2016-12-29  802.33  805.750  798.144  802.83   998255        0\n",
              "3114  2016-12-30  803.21  803.285  789.620  792.45  1735879        0\n",
              "\n",
              "[504 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkrOXw-dF4UM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "68e94649-de73-4843-f648-68a9a74f66a4"
      },
      "source": [
        "test_set"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>OpenInt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3115</th>\n",
              "      <td>2017-01-03</td>\n",
              "      <td>800.62</td>\n",
              "      <td>811.435</td>\n",
              "      <td>796.89</td>\n",
              "      <td>808.01</td>\n",
              "      <td>1932677</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3116</th>\n",
              "      <td>2017-01-04</td>\n",
              "      <td>809.89</td>\n",
              "      <td>813.430</td>\n",
              "      <td>804.11</td>\n",
              "      <td>807.77</td>\n",
              "      <td>1486687</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3117</th>\n",
              "      <td>2017-01-05</td>\n",
              "      <td>807.50</td>\n",
              "      <td>813.740</td>\n",
              "      <td>805.92</td>\n",
              "      <td>813.02</td>\n",
              "      <td>1305062</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3118</th>\n",
              "      <td>2017-01-06</td>\n",
              "      <td>814.99</td>\n",
              "      <td>828.960</td>\n",
              "      <td>811.50</td>\n",
              "      <td>825.21</td>\n",
              "      <td>1975843</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3119</th>\n",
              "      <td>2017-01-09</td>\n",
              "      <td>826.37</td>\n",
              "      <td>830.430</td>\n",
              "      <td>821.62</td>\n",
              "      <td>827.18</td>\n",
              "      <td>1365344</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3328</th>\n",
              "      <td>2017-11-06</td>\n",
              "      <td>1049.10</td>\n",
              "      <td>1052.590</td>\n",
              "      <td>1042.00</td>\n",
              "      <td>1042.68</td>\n",
              "      <td>913954</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3329</th>\n",
              "      <td>2017-11-07</td>\n",
              "      <td>1049.65</td>\n",
              "      <td>1053.410</td>\n",
              "      <td>1043.00</td>\n",
              "      <td>1052.39</td>\n",
              "      <td>1303832</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3330</th>\n",
              "      <td>2017-11-08</td>\n",
              "      <td>1050.05</td>\n",
              "      <td>1062.690</td>\n",
              "      <td>1047.05</td>\n",
              "      <td>1058.29</td>\n",
              "      <td>1214469</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3331</th>\n",
              "      <td>2017-11-09</td>\n",
              "      <td>1048.00</td>\n",
              "      <td>1050.880</td>\n",
              "      <td>1035.85</td>\n",
              "      <td>1047.72</td>\n",
              "      <td>1793994</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332</th>\n",
              "      <td>2017-11-10</td>\n",
              "      <td>1043.87</td>\n",
              "      <td>1046.630</td>\n",
              "      <td>1041.22</td>\n",
              "      <td>1044.15</td>\n",
              "      <td>970498</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>218 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date     Open      High      Low    Close   Volume  OpenInt\n",
              "3115  2017-01-03   800.62   811.435   796.89   808.01  1932677        0\n",
              "3116  2017-01-04   809.89   813.430   804.11   807.77  1486687        0\n",
              "3117  2017-01-05   807.50   813.740   805.92   813.02  1305062        0\n",
              "3118  2017-01-06   814.99   828.960   811.50   825.21  1975843        0\n",
              "3119  2017-01-09   826.37   830.430   821.62   827.18  1365344        0\n",
              "...          ...      ...       ...      ...      ...      ...      ...\n",
              "3328  2017-11-06  1049.10  1052.590  1042.00  1042.68   913954        0\n",
              "3329  2017-11-07  1049.65  1053.410  1043.00  1052.39  1303832        0\n",
              "3330  2017-11-08  1050.05  1062.690  1047.05  1058.29  1214469        0\n",
              "3331  2017-11-09  1048.00  1050.880  1035.85  1047.72  1793994        0\n",
              "3332  2017-11-10  1043.87  1046.630  1041.22  1044.15   970498        0\n",
              "\n",
              "[218 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipwE1rKA4Gpr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcceaca0-6f72-4c61-ebc4-1147f7a5ddfa"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(train_set.Close.values.tolist())\n",
        "dataset"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLhdaQzf4kbB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e706abbb-7bb8-40c7-81a2-6e6443240238"
      },
      "source": [
        "for elem in dataset:\n",
        "  print(elem.numpy())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "529.55\n",
            "519.46\n",
            "506.64\n",
            "505.15\n",
            "506.91\n",
            "500.72\n",
            "497.06\n",
            "501.8\n",
            "505.93\n",
            "504.01\n",
            "510.45\n",
            "509.94\n",
            "520.39\n",
            "537.3\n",
            "541.95\n",
            "536.72\n",
            "521.19\n",
            "512.43\n",
            "513.23\n",
            "537.55\n",
            "532.2\n",
            "533.3\n",
            "526.1\n",
            "529.83\n",
            "533.88\n",
            "529.28\n",
            "540.16\n",
            "538.0\n",
            "546.01\n",
            "551.16\n",
            "545.01\n",
            "542.65\n",
            "546.45\n",
            "541.8\n",
            "535.0\n",
            "538.65\n",
            "547.33\n",
            "559.29\n",
            "562.63\n",
            "575.02\n",
            "578.79\n",
            "578.33\n",
            "581.43\n",
            "572.9\n",
            "574.1\n",
            "559.85\n",
            "555.69\n",
            "561.36\n",
            "553.0\n",
            "561.64\n",
            "557.61\n",
            "566.16\n",
            "563.67\n",
            "564.95\n",
            "565.37\n",
            "577.54\n",
            "567.0\n",
            "563.64\n",
            "557.55\n",
            "561.14\n",
            "554.7\n",
            "549.49\n",
            "541.31\n",
            "543.95\n",
            "544.86\n",
            "548.84\n",
            "548.02\n",
            "548.54\n",
            "548.64\n",
            "539.78\n",
            "541.04\n",
            "543.52\n",
            "532.74\n",
            "544.53\n",
            "542.92\n",
            "549.18\n",
            "557.46\n",
            "573.66\n",
            "566.12\n",
            "564.37\n",
            "561.39\n",
            "548.77\n",
            "551.16\n",
            "552.84\n",
            "543.04\n",
            "535.08\n",
            "542.04\n",
            "548.95\n",
            "545.78\n",
            "538.73\n",
            "539.49\n",
            "549.2\n",
            "546.49\n",
            "546.67\n",
            "549.28\n",
            "552.51\n",
            "556.81\n",
            "554.52\n",
            "547.19\n",
            "554.25\n",
            "554.18\n",
            "545.32\n",
            "549.21\n",
            "553.95\n",
            "555.29\n",
            "551.69\n",
            "549.53\n",
            "543.48\n",
            "542.16\n",
            "552.6\n",
            "550.04\n",
            "547.47\n",
            "543.0\n",
            "544.87\n",
            "546.6\n",
            "556.18\n",
            "557.52\n",
            "559.68\n",
            "563.39\n",
            "558.57\n",
            "557.95\n",
            "553.06\n",
            "541.25\n",
            "540.04\n",
            "543.3\n",
            "547.34\n",
            "545.62\n",
            "550.03\n",
            "541.7\n",
            "544.65\n",
            "556.11\n",
            "571.73\n",
            "584.18\n",
            "583.96\n",
            "601.78\n",
            "699.62\n",
            "692.84\n",
            "695.35\n",
            "695.1\n",
            "674.73\n",
            "654.77\n",
            "658.27\n",
            "659.66\n",
            "661.43\n",
            "664.56\n",
            "657.5\n",
            "664.72\n",
            "661.28\n",
            "673.29\n",
            "670.15\n",
            "664.39\n",
            "663.14\n",
            "690.3\n",
            "691.47\n",
            "686.51\n",
            "689.37\n",
            "694.11\n",
            "688.73\n",
            "694.04\n",
            "679.48\n",
            "644.03\n",
            "618.11\n",
            "612.47\n",
            "659.74\n",
            "667.96\n",
            "659.69\n",
            "647.82\n",
            "629.56\n",
            "644.91\n",
            "637.05\n",
            "628.96\n",
            "643.88\n",
            "643.41\n",
            "651.08\n",
            "655.3\n",
            "652.47\n",
            "665.07\n",
            "665.52\n",
            "671.67\n",
            "660.92\n",
            "666.98\n",
            "653.2\n",
            "653.29\n",
            "654.91\n",
            "640.15\n",
            "624.25\n",
            "622.61\n",
            "638.37\n",
            "642.0\n",
            "656.99\n",
            "671.68\n",
            "671.64\n",
            "670.0\n",
            "667.0\n",
            "671.24\n",
            "676.43\n",
            "683.17\n",
            "680.41\n",
            "693.02\n",
            "695.32\n",
            "699.95\n",
            "680.0\n",
            "671.8\n",
            "681.14\n",
            "719.33\n",
            "731.12\n",
            "732.82\n",
            "736.92\n",
            "744.85\n",
            "737.39\n",
            "747.74\n",
            "748.82\n",
            "755.31\n",
            "760.67\n",
            "761.6\n",
            "754.77\n",
            "758.26\n",
            "765.25\n",
            "756.53\n",
            "740.07\n",
            "750.42\n",
            "745.98\n",
            "760.01\n",
            "759.94\n",
            "777.0\n",
            "776.7\n",
            "769.63\n",
            "769.26\n",
            "771.97\n",
            "762.85\n",
            "783.79\n",
            "777.85\n",
            "768.2\n",
            "779.21\n",
            "772.99\n",
            "775.14\n",
            "762.55\n",
            "760.04\n",
            "750.42\n",
            "762.54\n",
            "760.09\n",
            "776.59\n",
            "769.83\n",
            "756.85\n",
            "760.8\n",
            "767.13\n",
            "768.51\n",
            "765.84\n",
            "782.24\n",
            "793.96\n",
            "790.3\n",
            "778.01\n",
            "759.44\n",
            "761.53\n",
            "759.33\n",
            "741.0\n",
            "730.91\n",
            "733.07\n",
            "745.34\n",
            "719.57\n",
            "731.39\n",
            "710.49\n",
            "719.08\n",
            "718.56\n",
            "726.67\n",
            "745.46\n",
            "733.62\n",
            "733.79\n",
            "717.58\n",
            "748.3\n",
            "759.93\n",
            "770.77\n",
            "780.91\n",
            "749.38\n",
            "730.03\n",
            "703.76\n",
            "704.16\n",
            "701.02\n",
            "706.85\n",
            "706.36\n",
            "706.89\n",
            "717.64\n",
            "731.97\n",
            "717.51\n",
            "722.11\n",
            "729.05\n",
            "717.29\n",
            "720.9\n",
            "729.12\n",
            "724.86\n",
            "717.23\n",
            "742.17\n",
            "739.48\n",
            "731.59\n",
            "730.22\n",
            "712.8\n",
            "713.53\n",
            "725.41\n",
            "732.17\n",
            "744.87\n",
            "750.24\n",
            "750.57\n",
            "757.36\n",
            "758.48\n",
            "755.41\n",
            "762.16\n",
            "760.05\n",
            "757.56\n",
            "754.84\n",
            "753.28\n",
            "765.89\n",
            "768.34\n",
            "762.9\n",
            "769.67\n",
            "765.12\n",
            "758.57\n",
            "768.07\n",
            "760.12\n",
            "759.47\n",
            "757.54\n",
            "764.32\n",
            "771.91\n",
            "775.39\n",
            "780.0\n",
            "787.68\n",
            "776.25\n",
            "774.92\n",
            "781.14\n",
            "737.77\n",
            "742.21\n",
            "725.37\n",
            "721.46\n",
            "705.0\n",
            "707.88\n",
            "714.41\n",
            "708.44\n",
            "711.37\n",
            "714.71\n",
            "725.18\n",
            "729.13\n",
            "739.38\n",
            "730.55\n",
            "728.07\n",
            "724.83\n",
            "730.3\n",
            "720.13\n",
            "721.78\n",
            "715.31\n",
            "721.71\n",
            "717.25\n",
            "733.03\n",
            "738.1\n",
            "736.93\n",
            "747.64\n",
            "748.85\n",
            "748.46\n",
            "744.27\n",
            "735.86\n",
            "730.06\n",
            "731.09\n",
            "742.93\n",
            "742.52\n",
            "733.19\n",
            "731.88\n",
            "733.25\n",
            "732.19\n",
            "724.25\n",
            "704.26\n",
            "706.13\n",
            "708.88\n",
            "710.82\n",
            "714.87\n",
            "685.28\n",
            "681.14\n",
            "691.26\n",
            "695.19\n",
            "703.53\n",
            "710.25\n",
            "704.89\n",
            "708.97\n",
            "707.26\n",
            "717.78\n",
            "727.04\n",
            "732.51\n",
            "729.48\n",
            "735.78\n",
            "735.63\n",
            "753.2\n",
            "753.41\n",
            "757.08\n",
            "754.41\n",
            "759.28\n",
            "757.52\n",
            "757.65\n",
            "761.97\n",
            "765.84\n",
            "791.34\n",
            "801.23\n",
            "800.12\n",
            "798.82\n",
            "797.25\n",
            "806.93\n",
            "805.23\n",
            "807.48\n",
            "808.49\n",
            "808.2\n",
            "807.05\n",
            "805.96\n",
            "801.19\n",
            "805.42\n",
            "802.75\n",
            "799.65\n",
            "796.95\n",
            "796.59\n",
            "793.6\n",
            "791.3\n",
            "793.22\n",
            "795.82\n",
            "791.92\n",
            "789.85\n",
            "791.4\n",
            "796.87\n",
            "808.02\n",
            "807.99\n",
            "802.84\n",
            "788.48\n",
            "799.0\n",
            "788.72\n",
            "790.505\n",
            "801.29\n",
            "797.97\n",
            "795.39\n",
            "799.78\n",
            "804.56\n",
            "815.95\n",
            "814.96\n",
            "802.52\n",
            "810.73\n",
            "810.06\n",
            "802.64\n",
            "804.06\n",
            "800.38\n",
            "802.79\n",
            "801.23\n",
            "803.08\n",
            "800.71\n",
            "814.38\n",
            "809.57\n",
            "811.77\n",
            "804.08\n",
            "804.6\n",
            "806.84\n",
            "821.49\n",
            "827.09\n",
            "821.63\n",
            "824.06\n",
            "835.74\n",
            "828.55\n",
            "822.1\n",
            "817.35\n",
            "819.56\n",
            "809.9\n",
            "805.48\n",
            "788.42\n",
            "782.19\n",
            "781.1\n",
            "802.03\n",
            "811.98\n",
            "805.59\n",
            "780.29\n",
            "771.75\n",
            "753.22\n",
            "775.16\n",
            "779.98\n",
            "786.16\n",
            "775.97\n",
            "785.41\n",
            "785.0\n",
            "779.0\n",
            "780.15\n",
            "785.79\n",
            "789.44\n",
            "775.88\n",
            "764.33\n",
            "764.46\n",
            "778.22\n",
            "776.18\n",
            "791.47\n",
            "795.14\n",
            "809.45\n",
            "807.323\n",
            "815.34\n",
            "817.89\n",
            "815.65\n",
            "809.84\n",
            "812.51\n",
            "815.2\n",
            "812.2\n",
            "809.68\n",
            "807.8\n",
            "809.93\n",
            "804.57\n",
            "802.83\n",
            "792.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwypWEJUJ2qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, state_size, window_size, trend, skip, batch_size):\n",
        "        self.state_size = state_size\n",
        "        self.window_size = window_size\n",
        "        self.half_window = window_size // 2\n",
        "        self.trend = trend\n",
        "        self.skip = skip\n",
        "        self.action_size = 3\n",
        "        self.batch_size = batch_size\n",
        "        self.memory = deque(maxlen = 1000)\n",
        "        self.inventory = []\n",
        "\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 0.5\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.999\n",
        "\n",
        "\n",
        "        feed = tf.keras.dense(self.X, 256, activation = tf.nn.relu)\n",
        "        self.logits = tf.layers.dense(feed, self.action_size)\n",
        "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
        "        self.optimizer = tf.train.GradientDescentOptimizer(1e-5).minimize(\n",
        "            self.cost\n",
        "        )\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    def act(self, state):\n",
        "        if random.random() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        return np.argmax(\n",
        "            self.sess.run(self.logits, feed_dict = {self.X: state})[0]\n",
        "        )\n",
        "    \n",
        "    def get_state(self, t):\n",
        "        window_size = self.window_size + 1\n",
        "        d = t - window_size + 1\n",
        "        block = self.trend[d : t + 1] if d >= 0 else -d * [self.trend[0]] + self.trend[0 : t + 1]\n",
        "        res = []\n",
        "        for i in range(window_size - 1):\n",
        "            res.append(block[i + 1] - block[i])\n",
        "        return np.array([res])\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        mini_batch = []\n",
        "        l = len(self.memory)\n",
        "        for i in range(l - batch_size, l):\n",
        "            mini_batch.append(self.memory[i])\n",
        "        replay_size = len(mini_batch)\n",
        "        X = np.empty((replay_size, self.state_size))\n",
        "        Y = np.empty((replay_size, self.action_size))\n",
        "        states = np.array([a[0][0] for a in mini_batch])\n",
        "        new_states = np.array([a[3][0] for a in mini_batch])\n",
        "        Q = self.sess.run(self.logits, feed_dict = {self.X: states})\n",
        "        Q_new = self.sess.run(self.logits, feed_dict = {self.X: new_states})\n",
        "        for i in range(len(mini_batch)):\n",
        "            state, action, reward, next_state, done = mini_batch[i]\n",
        "            target = Q[i]\n",
        "            target[action] = reward\n",
        "            if not done:\n",
        "                target[action] += self.gamma * np.amax(Q_new[i])\n",
        "            X[i] = state\n",
        "            Y[i] = target\n",
        "        cost, _ = self.sess.run(\n",
        "            [self.cost, self.optimizer], feed_dict = {self.X: X, self.Y: Y}\n",
        "        )\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "        return cost\n",
        "    \n",
        "    def buy(self, initial_money):\n",
        "        starting_money = initial_money\n",
        "        states_sell = []\n",
        "        states_buy = []\n",
        "        inventory = []\n",
        "        state = self.get_state(0)\n",
        "        for t in range(0, len(self.trend) - 1, self.skip):\n",
        "            action = self.act(state)\n",
        "            next_state = self.get_state(t + 1)\n",
        "            \n",
        "            if action == 1 and initial_money >= self.trend[t] and t < (len(self.trend) - self.half_window):\n",
        "                inventory.append(self.trend[t])\n",
        "                initial_money -= self.trend[t]\n",
        "                states_buy.append(t)\n",
        "                print('day %d: buy 1 unit at price %f, total balance %f'% (t, self.trend[t], initial_money))\n",
        "                \n",
        "                \n",
        "            elif action == 2 and len(inventory):\n",
        "                bought_price = inventory.pop(0)\n",
        "                initial_money += self.trend[t]\n",
        "                states_sell.append(t)\n",
        "                try:\n",
        "                    invest = ((close[t] - bought_price) / bought_price) * 100\n",
        "                except:\n",
        "                    invest = 0\n",
        "                print(\n",
        "                    'day %d, sell 1 unit at price %f, investment %f %%, total balance %f,'\n",
        "                    % (t, close[t], invest, initial_money)\n",
        "                )\n",
        "            \n",
        "            state = next_state\n",
        "        invest = ((initial_money - starting_money) / starting_money) * 100\n",
        "        total_gains = initial_money - starting_money\n",
        "        return states_buy, states_sell, total_gains, invest\n",
        "        \n",
        "    def train(self, iterations, checkpoint, initial_money):\n",
        "        for i in range(iterations):\n",
        "            total_profit = 0\n",
        "            inventory = []\n",
        "            state = self.get_state(0)\n",
        "            starting_money = initial_money\n",
        "            for t in range(0, len(self.trend) - 1, self.skip):\n",
        "                action = self.act(state)\n",
        "                next_state = self.get_state(t + 1)\n",
        "                \n",
        "                if action == 1 and starting_money >= self.trend[t] and t < (len(self.trend) - self.half_window):\n",
        "                    inventory.append(self.trend[t])\n",
        "                    starting_money -= self.trend[t]\n",
        "                \n",
        "                elif action == 2 and len(inventory) > 0:\n",
        "                    bought_price = inventory.pop(0)\n",
        "                    total_profit += self.trend[t] - bought_price\n",
        "                    starting_money += self.trend[t]\n",
        "                    \n",
        "                invest = ((starting_money - initial_money) / initial_money)\n",
        "                self.memory.append((state, action, invest, \n",
        "                                    next_state, starting_money < initial_money))\n",
        "                state = next_state\n",
        "                batch_size = min(self.batch_size, len(self.memory))\n",
        "                cost = self.replay(batch_size)\n",
        "            if (i+1) % checkpoint == 0:\n",
        "                print('epoch: %d, total rewards: %f.3, cost: %f, total money: %f'%(i + 1, total_profit, cost,\n",
        "                                                                                  starting_money))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ku1_vf4vKus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0I5_hRKO-7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "e8f8809f-fb16-4ebc-db82-01110375a4f8"
      },
      "source": [
        "close = data.Close.values.tolist()\n",
        "initial_money = 10000\n",
        "window_size = 30\n",
        "skip = 1\n",
        "batch_size = 32\n",
        "agent = DQNAgent(state_size = window_size, \n",
        "              window_size = window_size, \n",
        "              trend = close, \n",
        "              skip = skip, \n",
        "              batch_size = batch_size)\n",
        "agent.train(iterations = 200, checkpoint = 10, initial_money = initial_money)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-cc1c82b8132b>:22: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "epoch: 10, total rewards: 182.010000.3, cost: 0.594407, total money: 10182.010000\n",
            "epoch: 20, total rewards: 22.143000.3, cost: 0.575513, total money: 10022.143000\n",
            "epoch: 30, total rewards: 49.528000.3, cost: 0.278911, total money: 10049.528000\n",
            "epoch: 40, total rewards: 171.943000.3, cost: 0.260734, total money: 10171.943000\n",
            "epoch: 50, total rewards: 332.648000.3, cost: 0.421622, total money: 10332.648000\n",
            "epoch: 60, total rewards: 261.710000.3, cost: 0.175892, total money: 10261.710000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2b22e7a82adb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m               batch_size = batch_size)\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_money\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_money\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-cc1c82b8132b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, checkpoint, initial_money)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mstarting_money\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_money\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrend\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-cc1c82b8132b>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         return np.argmax(\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         )\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2ausMvap8QQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}